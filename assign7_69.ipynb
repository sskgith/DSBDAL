{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "040bda86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'this', 'is', 'assignment', 'of', 'data', 'science']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#text preprocessing methods\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens=word_tokenize(\"Hello this is assignment of data science\")\n",
    "nltk.download('stopwords')\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3151c034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'assignment', 'data', 'science']\n"
     ]
    }
   ],
   "source": [
    "#to remove stopwords from the above sentence\n",
    "from nltk.corpus import stopwords\n",
    "stop_words=set(stopwords.words('english'))\n",
    "tokens = [w for w in tokens if not w in stop_words] #words writte in brackets are a short version of 2 for loops\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2234f307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Word--            --Stem--            \n",
      "program             program             \n",
      "programming         program             \n",
      "programer           program             \n",
      "programs            program             \n",
      "programmed          program             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#example for stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "# Initialize Python porter stemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# Example inflections to reduce\n",
    "example_words = [\"program\",\"programming\",\"programer\",\"programs\",\"programmed\"]\n",
    "\n",
    "# Perform stemming\n",
    "print(\"{0:20}{1:20}\".format(\"--Word--\",\"--Stem--\"))\n",
    "for word in example_words:\n",
    "    print(\"{0:20}{1:20}\".format(word, ps.stem(word)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ccc5ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Word--            --Lemma--           \n",
      "program             program             \n",
      "programming         program             \n",
      "programer           programer           \n",
      "programs            program             \n",
      "programmed          program             \n"
     ]
    }
   ],
   "source": [
    "#example for lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")\n",
    "# Initialize wordnet lemmatizer\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "# Example inflections to reduce\n",
    "example_words = [\"program\",\"programming\",\"programer\",\"programs\",\"programmed\"]\n",
    "\n",
    "# Perform lemmatization\n",
    "print(\"{0:20}{1:20}\".format(\"--Word--\",\"--Lemma--\"))\n",
    "for word in example_words:\n",
    "    print(\"{0:20}{1:20}\".format(word, wnl.lemmatize(word, pos=\"v\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40a4102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf for a sample\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14cf2c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'', 'Everyone', 'an', 'is', 'intelligent', 'not', 'girl', 'boy', 'He', 'She'}\n"
     ]
    }
   ],
   "source": [
    "first_sentence = \"He is an intelligent boy\"\n",
    "second_sentence = \"Everyone is not intelligent\"\n",
    "third_sentence=\"She is an intelligent girl \"\n",
    "first_sentence = first_sentence.split(\" \")\n",
    "second_sentence = second_sentence.split(\" \")\n",
    "third_sentence = third_sentence.split(\" \")\n",
    "total= set(first_sentence).union(set(second_sentence)).union(set(third_sentence))\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a65d1657",
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting total words and putting them in dataframe\n",
    "wordDictA = dict.fromkeys(total, 0) \n",
    "wordDictB = dict.fromkeys(total, 0)\n",
    "wordDictC=dict.fromkeys(total, 0)\n",
    "for word in first_sentence:\n",
    "    wordDictA[word]+=1\n",
    "    \n",
    "for word in second_sentence:\n",
    "    wordDictB[word]+=1\n",
    "    \n",
    "for word in third_sentence:\n",
    "    wordDictC[word]+=1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "07c83813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Everyone</th>\n",
       "      <th>an</th>\n",
       "      <th>is</th>\n",
       "      <th>intelligent</th>\n",
       "      <th>not</th>\n",
       "      <th>girl</th>\n",
       "      <th>boy</th>\n",
       "      <th>He</th>\n",
       "      <th>She</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Everyone  an  is  intelligent  not  girl  boy  He  She\n",
       "0  0         0   1   1            1    0     0    1   1    0\n",
       "1  0         1   0   1            1    1     0    0   0    0\n",
       "2  1         0   1   1            1    0     1    0   0    1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([wordDictA, wordDictB,wordDictC])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1775c17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Everyone        an        is  intelligent   not      girl  boy  \\\n",
      "0  0.000000      0.00  0.200000  0.200000     0.200000  0.00  0.000000  0.2   \n",
      "1  0.000000      0.25  0.000000  0.250000     0.250000  0.25  0.000000  0.0   \n",
      "2  0.166667      0.00  0.166667  0.166667     0.166667  0.00  0.166667  0.0   \n",
      "\n",
      "    He       She  \n",
      "0  0.2  0.000000  \n",
      "1  0.0  0.000000  \n",
      "2  0.0  0.166667  \n"
     ]
    }
   ],
   "source": [
    "#calculatin TF function\n",
    "def computeTF(wordDict, doc):\n",
    "    tfDict = {}\n",
    "    corpusCount = len(doc)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count/float(corpusCount)\n",
    "    return(tfDict)#running our sentences through the tf function:\n",
    "tfFirst = computeTF(wordDictA, first_sentence)\n",
    "tfSecond = computeTF(wordDictB, second_sentence)\n",
    "tfThird = computeTF(wordDictC, third_sentence)#Converting to dataframe for visualization\n",
    "tf = pd.DataFrame([tfFirst, tfSecond,tfThird])\n",
    "print(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6ee974af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'Everyone', 'intelligent', 'girl', 'boy', 'He', 'She']\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_sentence = [w for w in wordDictA if not w in stop_words]\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "82fa2a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'': 0.47712125471966244, 'Everyone': 0.47712125471966244, 'an': 0.47712125471966244, 'is': 0.47712125471966244, 'intelligent': 0.47712125471966244, 'not': 0.47712125471966244, 'girl': 0.47712125471966244, 'boy': 0.47712125471966244, 'He': 0.47712125471966244, 'She': 0.47712125471966244}\n"
     ]
    }
   ],
   "source": [
    "def computeIDF(docList):\n",
    "    idfDict = {}\n",
    "    N = len(docList)\n",
    "    \n",
    "    idfDict = dict.fromkeys(docList[0].keys(), 0)\n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log10(N / (float(val) + 1))\n",
    "        \n",
    "    return(idfDict)#inputing our sentences in the log file\n",
    "idfs = computeIDF([wordDictA, wordDictB,wordDictC])\n",
    "print(idfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "45180872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Everyone        an        is  intelligent      not     girl  \\\n",
      "0  0.00000   0.00000  0.095424  0.095424     0.095424  0.00000  0.00000   \n",
      "1  0.00000   0.11928  0.000000  0.119280     0.119280  0.11928  0.00000   \n",
      "2  0.07952   0.00000  0.079520  0.079520     0.079520  0.00000  0.07952   \n",
      "\n",
      "        boy        He      She  \n",
      "0  0.095424  0.095424  0.00000  \n",
      "1  0.000000  0.000000  0.00000  \n",
      "2  0.000000  0.000000  0.07952  \n"
     ]
    }
   ],
   "source": [
    "def computeTFIDF(tfBow, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBow.items():\n",
    "        tfidf[word] = val*idfs[word]\n",
    "    return(tfidf)\n",
    "#running our two sentences through the IDF:\n",
    "idfFirst = computeTFIDF(tfFirst, idfs)\n",
    "idfSecond = computeTFIDF(tfSecond, idfs)\n",
    "idfThird = computeTFIDF(tfThird, idfs)\n",
    "#putting it in a dataframe\n",
    "idf= pd.DataFrame([idfFirst, idfSecond,idfThird])\n",
    "print(idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5586bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
